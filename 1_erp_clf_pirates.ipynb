{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfb9a2ed-8692-4075-8b62-96e19f26f770",
   "metadata": {},
   "source": [
    "# Machine Learning Classifier Evaluation\n",
    "\n",
    "Fit a support vector machine (SVM) ML classifier to each subject in the Flickering Oddball Stimulation Method (FOSM) study, and compute performance evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc9d31-4020-4ce7-b6c5-54c22211d214",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21a12e0-921b-461a-8ac3-99d66cb7c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from os import path as op\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from yaml import CLoader as Loader\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "from glob import glob\n",
    "# MNE\n",
    "import mne\n",
    "from mne.decoding import Vectorizer, get_coef, LinearModel\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import PrecisionRecallDisplay, ConfusionMatrixDisplay, classification_report, make_scorer, balanced_accuracy_score, fbeta_score, precision_recall_curve, precision_score, recall_score, accuracy_score, roc_auc_score, f1_score, matthews_corrcoef, confusion_matrix\n",
    "    # Classifiers\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "mne.set_log_level(verbose='Warning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ab46a-5a70-4f49-a635-c238688f278e",
   "metadata": {},
   "source": [
    "## Yaml + Pathing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83370f26-b562-4e57-bcde-f0fc3d86ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## YAML\n",
    "with open('config.yml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=Loader)\n",
    "\n",
    "study_name = config['study_name']\n",
    "task = config['task']\n",
    "data_type = config['data_type']\n",
    "eog = config['eog']\n",
    "montage_fname = config['montage_fname']\n",
    "n_jobs = -1\n",
    "\n",
    "epoch_p =  {k: v for d in config['preprocessing_settings']['epoch'] for k, v in d.items()}\n",
    "\n",
    "cl_p = {k: v for d in config['classification'] for k, v in d.items()}\n",
    "\n",
    "## Pathing\n",
    "results_path = op.join('results', 'classification_test_' + str(cl_p['test_size'])[-1] + '0_pct')\n",
    "if Path(results_path).exists() == False:\n",
    "    Path(results_path).mkdir(parents=True)\n",
    "\n",
    "tab_path = op.join(results_path, 'tables')\n",
    "if Path(tab_path).exists() == False:\n",
    "    Path(tab_path).mkdir(parents=True) \n",
    "    \n",
    "epochs_suffix = '-epo.fif'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e6edc3-eac1-4eef-8654-3ec539022b40",
   "metadata": {},
   "source": [
    "## Define conditions and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa02dd-320e-49d0-b3fe-e13c8517cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['Neutral/Upright/Faces/Target','Neutral/Upright/Faces/Standard',\n",
    "              'Neutral/Upright/Silhouettes/Target','Neutral/Upright/Silhouettes/Standard',\n",
    "              \n",
    "              'Green/Upright/Faces/Target','Green/Upright/Faces/Standard',\n",
    "              'Green/Upright/Silhouettes/Target','Green/Upright/Silhouettes/Standard',\n",
    "              \n",
    "              'Neutral/Inverted/Faces/Target','Neutral/Inverted/Faces/Standard',\n",
    "              'Neutral/Inverted/Silhouettes/Target','Neutral/Inverted/Silhouettes/Standard',\n",
    "              \n",
    "              'Green/Inverted/Faces/Target','Green/Inverted/Faces/Standard',\n",
    "              'Green/Inverted/Silhouettes/Target','Green/Inverted/Silhouettes/Standard',\n",
    "              \n",
    "              'Target', 'Standard'\n",
    "             ]\n",
    "\n",
    "coi = ['Target', 'Standard']\n",
    "\n",
    "contrasts = {'Neutral/Upright/Faces':['Neutral/Upright/Faces/Target','Neutral/Upright/Faces/Standard'],\n",
    "             'Neutral/Upright/Silhouettes':['Neutral/Upright/Silhouettes/Target','Neutral/Upright/Silhouettes/Standard'],\n",
    "             \n",
    "             'Green/Upright/Faces':['Green/Upright/Faces/Target','Green/Upright/Faces/Standard'],\n",
    "             'Green/Upright/Silhouettes':['Green/Upright/Silhouettes/Target','Green/Upright/Silhouettes/Standard'],\n",
    "             \n",
    "             'Neutral/Inverted/Faces':['Neutral/Inverted/Faces/Target','Neutral/Inverted/Faces/Standard'],\n",
    "             'Neutral/Inverted/Silhouettes':['Neutral/Inverted/Silhouettes/Target','Neutral/Inverted/Silhouettes/Standard'],\n",
    "             \n",
    "             'Green/Inverted/Faces':['Green/Inverted/Faces/Target','Green/Inverted/Faces/Standard'],\n",
    "             'Green/Inverted/Silhouettes':['Green/Inverted/Silhouettes/Target','Green/Inverted/Silhouettes/Standard'],\n",
    "             \n",
    "             'Target-Nontarget':['Target', 'Standard']\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c75a743-44bd-4e6e-b4c1-d49a4be1c61e",
   "metadata": {},
   "source": [
    "## Instantiating classifiers, parameter grids, and scoring metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf465a-18fd-48e7-81a3-76a02df33e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "vectorizer = Vectorizer()\n",
    "\n",
    "svm = LinearSVC(random_state=42, max_iter=5000, dual=True)\n",
    "\n",
    "svm_params = {\n",
    "    'SVM__C': np.logspace(-4, 3, num=30, dtype=float),\n",
    "    'SVM__class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "\n",
    "classifiers = {'SVM': {svm:svm_params}}\n",
    "\n",
    "## SCORING\n",
    "scoring = {'Prec': make_scorer(precision_score, zero_division=0),\n",
    "           'Bal_Acc': make_scorer(balanced_accuracy_score),\n",
    "           'Acc': make_scorer(accuracy_score),\n",
    "           'Recall': make_scorer(recall_score),\n",
    "           'ROC': make_scorer(roc_auc_score),\n",
    "           'Matthews_Coef': make_scorer(matthews_corrcoef),\n",
    "           'Fbeta_0.5': make_scorer(fbeta_score, beta = 0.5),\n",
    "           'Fbeta_1.5': make_scorer(fbeta_score, beta = 1.5),\n",
    "           'F1_score': make_scorer(f1_score, zero_division=0)\n",
    "          }\n",
    "\n",
    "## Which scoring metric will RandomizedSearchCV refit for? (Case-sensitive); must be one of the above^\n",
    "refit = 'Matthews_Coef'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d2db4-d480-44f3-8c00-d6ce0b6ac728",
   "metadata": {},
   "source": [
    "## Subjects + Loading em' in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87ec5a-d8b4-452e-8186-e3e482d634a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For Running Individual participants\n",
    "subjects = ['sub-004', 'sub-005']\n",
    "print(\"n subjects = \", len(subjects))\n",
    "\n",
    "## Reading in data\n",
    "epochs = {}\n",
    "print('Loading Subjects:', subjects)\n",
    "for subject in subjects:\n",
    "    raw_path = op.join('./', 'data')\n",
    "    raw_subj = glob(op.join(raw_path + '/' + '*-epo.fif'))\n",
    "    epochs[subject] = mne.read_epochs(raw_subj.pop(), proj=False, verbose=False, preload=True)\n",
    "    \n",
    "    # Correcting for presentation delay\n",
    "    epochs[subject]._raw_times = epochs[subject]._raw_times - epoch_p['tshift']\n",
    "    epochs[subject]._times_readonly = epochs[subject]._times_readonly - epoch_p['tshift']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d239826-3a56-4b90-aaad-4bdd8bef8fd3",
   "metadata": {},
   "source": [
    "### Batch Classification Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde30452-6b7c-4e4a-a191-fde2aecb8964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%xmode Verbose\n",
    "\n",
    "# Making the cross-validation to be used in the RandomizedSearch\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for subject in subjects:\n",
    "    print('\\n-------\\n\\033[;40m' + subject + '\\033[m')\n",
    "    \n",
    "    # Clearing out the saved data for each participant\n",
    "    data_table = pd.DataFrame()\n",
    "    data_table_list = []\n",
    "    \n",
    "    for contr, conds in contrasts.items():\n",
    "        print('-------\\n\\033[94;40m' + contr + '\\033[m')\n",
    "        subj_epochs = epochs[subject][conds]\n",
    "        \n",
    "        # Create a list of labels from event codes mapped to event_id\n",
    "        event_id_rev = dict(zip(subj_epochs.event_id.values(), subj_epochs.event_id.keys()))\n",
    "        labels_all = [event_id_rev[e] for e in subj_epochs.events[:, 2]]\n",
    "        labels_all = pd.DataFrame(labels_all)[0].str.split('/', expand=True).rename(columns={0:'Colour', 1:'Orientation', 2:'Type', 3:'Status', 4:'Location'} )\n",
    "        label_map = {'Target':1, 'Standard':0}\n",
    "        labels_all['labels'] = labels_all['Status'].map(label_map)\n",
    "        labels = labels_all['labels']\n",
    "        \n",
    "        # Extract data from subj_epochs and vectorize \n",
    "        D = subj_epochs.get_data()\n",
    "        \n",
    "        # Create train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(D, \n",
    "                                                            labels,\n",
    "                                                            stratify=labels,\n",
    "                                                            test_size=cl_p['test_size'], \n",
    "                                                            random_state=42,\n",
    "                                                            shuffle=True\n",
    "                                                           )\n",
    "\n",
    "        # FUNKY DICTIONARY MAGIC, WHOA!\n",
    "        for c_name in classifiers.keys():\n",
    "            for clf, params in classifiers[c_name].items():\n",
    "                print('-------\\nRunning classifier: \\033[1;91;40m' + c_name + '\\033[m')\n",
    "                \n",
    "                # Making the Pipeline for GridSearchCV\n",
    "                pipe = Pipeline([('Vectorizer', vectorizer),\n",
    "                                 ('Scaler', scaler),\n",
    "                                 (c_name, clf)                                 \n",
    "                                 ])\n",
    "\n",
    "                # Hyperparemter Tuning with RandomizedSearchCV\n",
    "                gs = RandomizedSearchCV(pipe,\n",
    "                                        svm_params,\n",
    "                                        cv=cv,\n",
    "                                        scoring=scoring,\n",
    "                                        refit=refit,\n",
    "                                        return_train_score=True, # Determines if Training scores are included in .cv_results_\n",
    "                                        n_jobs=n_jobs,\n",
    "                                        error_score='raise' # For debugging purposes\n",
    "                                        )\n",
    "                \n",
    "                print('Searching and Selecting Optimal Hyperparameters...')\n",
    "                gs.fit(X_train, y_train)\n",
    "\n",
    "                print('Predicting with Chosen Hyperparameters:', gs.best_params_)\n",
    "                y_pred = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "                print('Scoring...')        \n",
    "                print(classification_report(y_test, y_pred))\n",
    "                \n",
    "                # Confusion Matrix Generation and Visualization within the loop -> saved to csv as \"[[TN, FN] [FP, TP]]\"\n",
    "                cm = confusion_matrix(y_test, y_pred, labels=gs.classes_)\n",
    "                cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gs.classes_)\n",
    "                cmd.plot()\n",
    "                plt.title(subject + '_' + str(contr).replace('/', '_') + '_' + c_name)\n",
    "                plt.show()\n",
    "\n",
    "                # Saving CV results to a DataFrame \n",
    "                results = pd.DataFrame(gs.cv_results_)\n",
    "                \n",
    "                data_table_list.append(pd.DataFrame({'participant_id': subject,\n",
    "                                                  'Condition': contr,\n",
    "                                                  'Classifier': c_name,\n",
    "                                                  'Parameters Used': str(gs.best_params_),\n",
    "                                                   \n",
    "                                                  # Confusion_matrix saved in format: [[TN, FN] [FP, TP]]\n",
    "                                                  'Confusion_Matrix': str(cm),                                                 \n",
    "                                                  \n",
    "                                                  'CV_Train_Bal_Accuracy': results['mean_train_Bal_Acc'].round(3) * 100,\n",
    "                                                  'CV_Test_Bal_Accuracy': results['mean_test_Bal_Acc'].round(3) * 100,\n",
    "                                                  'Test_Bal_Accuracy': round(balanced_accuracy_score(y_test, y_pred), 3) * 100,\n",
    "                                                  \n",
    "                                                  'CV_Train_Accuracy': results['mean_train_Acc'].round(3) * 100,\n",
    "                                                  'CV_Test_Accuracy': results['mean_test_Acc'].round(3) * 100,\n",
    "                                                  'Test_Accuracy': round(accuracy_score(y_test, y_pred), 3) * 100, \n",
    "                                                  \n",
    "                                                  'CV_Train_Precision': results['mean_train_Prec'].round(3) * 100,\n",
    "                                                  'CV_Test_Precision': results['mean_test_Prec'].round(3) * 100,                                                \n",
    "                                                  'Test_Precision': round(precision_score(y_test, y_pred, zero_division=0), 3) * 100,    \n",
    "                                                     \n",
    "                                                  'CV_Train_Matthews_coef':results['mean_train_Matthews_Coef'].round(3),\n",
    "                                                  'CV_Test_Matthews_coef':results['mean_test_Matthews_Coef'].round(3),\n",
    "                                                  'Matthews_Coef': round(matthews_corrcoef(y_test, y_pred), 3),\n",
    "\n",
    "                                                  'CV_Train_Recall':results['mean_train_Recall'].round(3) * 100,\n",
    "                                                  'CV_Test_Recall': results['mean_test_Recall'].round(3) * 100,\n",
    "                                                  'Test_recall': round(recall_score(y_test, y_pred), 3) * 100,\n",
    "                                                  \n",
    "                                                  'CV_Train_Fbeta_0.5':results['mean_train_Fbeta_0.5'].round(3),\n",
    "                                                  'CV_Train_Fbeta_0.5':results['mean_train_Fbeta_0.5'].round(3),\n",
    "                                                  'Fbeta_0.5': round(fbeta_score(y_test, y_pred, beta = 0.5, zero_division=0), 3),\n",
    "                                                  \n",
    "                                                  'CV_Train_Fbeta_1.5':results['mean_train_Fbeta_1.5'].round(3),\n",
    "                                                  'CV_Test_Fbeta_1.5':results['mean_test_Fbeta_1.5'].round(3),\n",
    "                                                  'Fbeta_1.5': round(fbeta_score(y_test, y_pred, beta = 1.5, zero_division=0), 3),\n",
    "                                                  \n",
    "                                                  'CV_Train_F1':results['mean_train_F1_score'].round(3),\n",
    "                                                  'CV_Test_F1': results['mean_test_F1_score'].round(3),\n",
    "                                                  'F1_score': round(f1_score(y_test, y_pred, zero_division=0), 3),\n",
    "                                                  \n",
    "                                                  'CV_Train_ROC_AUC':results['mean_train_ROC'].round(3),\n",
    "                                                  'CV_Test_ROC_AUC': results['mean_test_ROC'].round(3),                                             \n",
    "                                                  'Test_ROC_AUC': round(roc_auc_score(y_test, y_pred), 3),\n",
    "\n",
    "                                                  'Mean Fit Time': results['mean_fit_time'].round(3),\n",
    "                                                  'Mean Score Time': results['mean_score_time'].round(3)\n",
    "                                                 }, index=[0]\n",
    "                                                )\n",
    "                                   )\n",
    "\n",
    "    # Saving Data to CSV Per Participant\n",
    "    data_table = pd.concat(data_table_list)\n",
    "    data_table.to_csv('./results/classification_test_20_pct/tables/' + str(subject) + '_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncil",
   "language": "python",
   "name": "ncil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
